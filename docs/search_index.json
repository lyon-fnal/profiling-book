[
["index.html", "Time Profiling Preface", " Time Profiling Adam L. Lyon (Fermilab/SCD) 2017-05-02 Preface Optimizing code for speed and memory is extremely important for HEP applications. This document will explain some process and tools available for profiling the time a program takes. "],
["intro.html", "1 Introduction", " 1 Introduction As a friend of mine once said, “If it isn’t instantaneous, then your code is too slow”. While instantaneous applications are unfortunately unrealistic, it is important for your code to run as fast as possible. Therefore, it is important to measure how long your code takes to run and use tools to understand where time is being spent and to find bottlenecks. For this document, we’ll use the Muon g-2 Geant based ring simulation. There were hints that a recent release of the software, gm2 v7_03_00 was significantly slower than and older version gm2 v6_04_00. The differences between the versions are using much new versions of art, Geant4, and Root. Furthermore, Geant4 gm2 v7_03_00 is using a new geometry and transportation system called USolids. There was a lot of worry that the slowness was because one of these updated external libraries was much slower than before. If that is indeed the case, it may be difficult to make the code faster. Furthermore, there is another slow down in the simulation between gm2 v7_05_00 and gm2 v7_04_00. That will be explored in the chapter about igprof. The following chapters will describe how to use various tools to learn more about the speed of your code, using the example mentioned above. "],
["time-command.html", "2 time command", " 2 time command One of the first things you should do is measure the total time your program takes. Doing so is easy with the Linux time command. time &lt;command&gt; For example, if I run this on the gm2 v6_04_00 code, I get, time gm2 -c mdc0.fcl -n 500 # lots of output from the program above&gt; # for gm2 v6_04_00 real 2m1.455s user 2m1.518s sys 0m1.282s The real time is the actual wall clock time the program took to complete. So when you issued the command, it took 2 minutes 1.45 seconds to run. The user and sys time represent how much time the machine’s processors were spending on non-kernel functions and kernel functions respectively. Kernel functions involve low-level OS operations like I/O. Given that most of our programs are computationally intensive, you should the the vast majority of time taken in user. If the program involves a lot of I/O, then the real time may be significantly more than user time due to waiting for disk reads and writes. I am using a virtual machine for these examples. If you are using a shared machine and there is significant additional activity on the machine, then that will also increase the real time. Note that you see that the real wall clock time is slightly less than the user time, which may seem to make little sense. In fact, user and sys time are the total time taken by all processors. Because the MessageFacility of art runs in a separate thread, there are actually two processors spending time. Thus, the total time may be more than the real wall clock time. Here is the output for gm2 v7_03_00, # for gm2 v7_03_00 real 5m33.849s user 8m15.264s sys 0m37.830s Indeed by wall clock time, the new version of gm2 takes almost three times longer than the old version! It is interesting to note that the sys time is significant larger in the new version and the user time is much larger than the real time. These results may be hints that the MessageFacility thread is using much more time in the v7 version of gm2 than v6. We can try to confirm this suspicion and understand why with more advanced tools. "],
["module-and-event-timing.html", "3 Module and event timing 3.1 Summary printout 3.2 Database", " 3 Module and event timing A next step could be to understand how long time is being spent in particular art modules and on a more event by event level. Because the bulk of the simulation runs in the artg4 producer, this measurement may be less useful compared to a many module art job. But it will still be instructive so it is good to do. The TimeTracker art service provides timing information about each module and statistics over events. It can also create a database with event by event timing information. You can run TimeTracker by adding the following to your FCL file… services : { // ... TimeTracker : { printSummary : true dbOutput : { filename : &quot;v7_timing.db&quot; overwrite : true } } // ... } See http://cdcvs.fnal.gov/redmine/projects/art/wiki/TimeTracker for more information and instructions. 3.1 Summary printout The default usage of the service and the configuration described here prints out a summary of timing information at the end of the job. For our example comparing gm2 v6_04_00 and gm2 v7_03_00, we get the following output… # v6_04_00 TimeReport ---------- Time Summary ---[sec]---- TimeReport CPU = 48.492349 Real = 48.291652 ================================================================================================================================ TimeTracker printout (sec) Min Avg Max Median RMS nEvts ================================================================================================================================ Full event 0.00430586 0.0969926 0.979898 0.0567863 0.111273 500 -------------------------------------------------------------------------------------------------------------------------------- path1:randomsaver:RandomNumberSaver 1.5818e-05 2.97016e-05 0.000218545 2.39715e-05 1.6956e-05 500 path1:artg4:artg4Main 0.00312922 0.0931658 0.970814 0.0553228 0.108083 500 path1:TriggerResults:TriggerResultInserter 9.438e-06 1.54518e-05 9.9472e-05 1.2985e-05 8.65874e-06 500 end_path:out1:RootOutput 0.000232495 0.00371359 0.163321 0.00142215 0.00797466 500 ================================================================================================================================ and # v7_03_00 TimeReport ---------- Time Summary ---[sec]---- TimeReport CPU = 457.772410 Real = 259.748750 ================================================================================================================================ TimeTracker printout (sec) Min Avg Max Median RMS nEvts ================================================================================================================================ Full event 0.0103769 0.519505 4.16775 0.257809 0.594227 500 -------------------------------------------------------------------------------------------------------------------------------- path1:randomsaver:RandomNumberSaver 3.2923e-05 5.95679e-05 0.00119983 4.83085e-05 5.79987e-05 500 path1:artg4:artg4Main 0.01027 0.519357 4.16762 0.257689 0.594228 500 path1:TriggerResults:TriggerResultInserter 1.7502e-05 2.29663e-05 9.7601e-05 2.09805e-05 7.6282e-06 500 end_path:out1:RootOutput 2.405e-06 3.71508e-06 2.0902e-05 3.5705e-06 1.11764e-06 500 end_path:out1:RootOutput(write) 0.000217776 0.00289537 0.0216031 0.00107864 0.0031938 500 ================================================================================================================================ Note the statistics for events. The only producer that really matters here is artg4::artg4Main, which runs Geant. On average, for v6 we see it took Geant 0.093s/muon and for v7 we see it took Geant 0.52s/muon. This is a dramatic difference. It is also interesting to look at the extremes - there was an event run by v7 that took over four seconds! 3.2 Database As shown in the FCL fragment above, TimeTracker can optionally output a database with timing information for each event. Let’s look at the timing information for v7. For the analysis we’ll use R. library(tidyverse) db &lt;- src_sqlite(&quot;data/v7_timing.db&quot;) db ## src: sqlite 3.11.1 [data/v7_timing.db] ## tbls: TimeEvent, TimeModule, TimeReport The TimeEvent table has the total time for each event. te &lt;- tbl(db, &quot;TimeEvent&quot;) te %&gt;% collect() ## # A tibble: 500 × 4 ## Run Subrun Event Time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 0 1 0.04066667 ## 2 1 0 2 2.11977645 ## 3 1 0 3 1.11163810 ## 4 1 0 4 0.02122142 ## 5 1 0 5 0.01811102 ## 6 1 0 6 1.90626422 ## 7 1 0 7 1.49305715 ## 8 1 0 8 1.78778369 ## 9 1 0 9 0.35362362 ## 10 1 0 10 0.03596895 ## # ... with 490 more rows The TimeModule table has the time for each event broken down by module. tm &lt;- tbl(db, &quot;TimeModule&quot;) tm %&gt;% collect() ## # A tibble: 2,500 × 5 ## Run Subrun Event PathModuleId ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 1 0 1 path1:randomsaver:RandomNumberSaver ## 2 1 0 1 path1:artg4:artg4Main ## 3 1 0 1 path1:TriggerResults:TriggerResultInserter ## 4 1 0 1 end_path:out1:RootOutput ## 5 1 0 1 end_path:out1:RootOutput(write) ## 6 1 0 2 path1:randomsaver:RandomNumberSaver ## 7 1 0 2 path1:artg4:artg4Main ## 8 1 0 2 path1:TriggerResults:TriggerResultInserter ## 9 1 0 2 end_path:out1:RootOutput ## 10 1 0 2 end_path:out1:RootOutput(write) ## # ... with 2,490 more rows, and 1 more variables: Time &lt;dbl&gt; The TimeReport table gives the same information as the printed output from the TimeTracker service. tr &lt;- tbl(db,&quot;TimeReport&quot;) tr %&gt;% collect() ## # A tibble: 6 × 7 ## ReportType Min Mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Full event 0.011088641 5.674523e-01 ## 2 path1:randomsaver:RandomNumberSaver 0.000036479 7.262060e-05 ## 3 path1:artg4:artg4Main 0.010938725 5.672769e-01 ## 4 path1:TriggerResults:TriggerResultInserter 0.000019366 2.520183e-05 ## 5 end_path:out1:RootOutput 0.000003411 4.426006e-06 ## 6 end_path:out1:RootOutput(write) 0.000236947 3.200830e-03 ## # ... with 4 more variables: Max &lt;dbl&gt;, Median &lt;dbl&gt;, RMS &lt;dbl&gt;, ## # nEvts &lt;int&gt; We can make plots… tm %&gt;% filter(PathModuleId == &#39;path1:artg4:artg4Main&#39;) %&gt;% collect() -&gt; artg4Time artg4Time %&gt;% ggplot( aes(x=Event, y=Time) ) + geom_point() artg4Time %&gt;% ggplot( aes(x=Time) ) + geom_histogram(bins=50) "],
["time-profiling-with-igprof.html", "4 Time Profiling with igprof 4.1 Running igprof 4.2 Interpreting igprof timing results from web page 4.3 Another analysis", " 4 Time Profiling with igprof igprof (see http://igprof.org) is a powerful profiling application that was originally written for the CMS experiment. igprof is available in CVMFS. As of this writing, you can set it up with setup igprof v5_9_16 -q e10. igprof can do time and memory profiling. We will concentrate on the time performance profiling for this chapter. An advantage of igprof is that it does not access the source code at all (unlike allinea). So you can run igprof on releases without having to check out any code. Of course profiling any fixes and changes will require the source code and builds. 4.1 Running igprof With an environment already set up, including igprof (see above), you can run the time profiling with, for example, … igprof -pp -d -z -t gm2 -o &lt;igprof.pp.gz&gt; gm2 -c theFCL.fcl -n 500 The options mean… -pp Do time profiling -d add more details (like demangling c++ names) -z compress the output -t &lt;app&gt; only look at a process named app -o &lt;file&gt; write output to file The rest of the arguments are the program to run with its options For example, igprof -pp -d -z -t gm2 -o v7_05_mdc1_igprof.gz gm2 -c mdc1.fcl -n 500 The output file is generally not human readable. You need to run igprof-analyze to put it in a more readable form. You can make an ASCII file or an sqlite database that can be browsed with another tool. I prefer the latter option and so that process will be explained here. See http://igprof.org/analysis.html and http://igprof.org/text-output-format.html for information about ASCII output. To make the database, do, igprof-analyse --sqlite -d -g -v &lt;igprof.pp.gz&gt; | sqlite3 &lt;out.db&gt; The options mean… -d -g and more demangling information -v verbose mode For example, unsetup python # the ups python interferes igprof-analyse --sqlite -d -g -v v7_05_mdc1_igprof.gz | sqlite3 v7_05_mdc1_igprof.db Now that you have the database, you can run igprof-navigator to browse the timings with your web browser. To set that up, run, igprof-navigator &lt;out.db&gt; -p &lt;port&gt; For example, igprof-navigator v7_05_mdc1_igprof.db -p 8080 The application will print the URL, but note that only the port is correct. You will likely need to port forward to access the web page and do, e.g., http://localhost:8080. Be sure to stop the server when you are finished with Ctrl-C. 4.2 Interpreting igprof timing results from web page See the previous section for setting up, running igprof, and setting up the navigator web server. We’ll go through an example using the g-2 simulation program. Figure 4.1: First page The top web page is shown in Fig. 4.1, and it shows the cumulative “cost” of called functions in the program. Cumulative means the time spent in that function in seconds, and all of the functions it calls (so the top function takes all of the running time). All of the functions on top are infrastructure for art, but those should be really fast. The best strategy is to look for drops in Cumulative time. Where there’s a drop means that some code as branched off and is taking time. Let’s start with that. The first drop is between items #7 and #8. Something took almost 90s to run. Let’s figure that out. Click on the 7 (or the corresponding name of the function). Figure 4.2: First branch point Figure 4.2 shows the new page. All of the detailed pages will look like this, so let’s go through it. The beige background row is the function under scrutiny (the one you clicked on to get here) The rows above (dark green) are functions that call the scrutinized function The rows below (light green) are functions that are called by the scrutinized function The Rank column is only for the scrutinized function and shows where it is in the cumulative timings of all the functions. So art::run_art_common_ is the 7th most time consuming function of the program. The %total column shows the fraction of all time of the program spent in that particular function including all functions that is calls (cumulative!). The Counts column shows how many seconds are spent in the function for different circumstances. For the caller functions (dark green), to/from shows the time spent in the caller function waiting for the scrutinized function to return. Total includes the time the caller function takes. For the scrutinized function (beige), to/from shows the time spent only in the scrutinized function alone. Total includes the time in the functions it calls (so art::run_art_common_ itself takes no time – all of the time is spent in functions that it calls), For the called functions (light green), both columns show the same thing and that’s how many seconds are spent in the called function and all functions they call (cumulative). The Paths column is not interesting for our purposes here. So for our example, the 90 seconds goes into art::EventProcessor::EventProcessor - the constructor for EventProcessor. The next thing to do is to click on that function and then keep clicking on the 90s function until we see something interesting. It takes many clicks. Figure 4.3: Detector builders We finally get to Fig. 4.3 where we see where the 90s goes. It is split among the functions that build detectors when the program starts. As expected, the CadMesh functions take the most time. We could click on the most expensive function gm2ringsim::StrawTrackerCadMesh, and see where its time goes. As expected, it’s all in CadMesh as shown in Fig. 4.4. Figure 4.4: CadMesh So here you see that almost all of the 90s is taken up by CADMesh::TessellatedMesh and that’s called by various other functions. So the upshot here is that the target of work for speedup should be CADMesh::TessellatedMesh itself. 4.3 Another analysis We’ve just figured out the cost of staring the simulation. Fortunately, that’s a one time cost. Let’s go back and look at the main cause of time spent generating events. In Fig. 4.2, we see that art::EventProcessor::runToCompletion takes up the most time. That is the function that generates events. Anything in here that takes time gets amplified by the number of events the simulation is producing. Let’s look to see if anything stands out. Click on art::EventProcessor::runToCompletion and keep clicking on the called function that takes the longest. Figure 4.5: Field Lookups Eventually we get to Fig. 4.5. We see that gm2geom::gm2FieldManager::GetUnifiedField takes up 40% of the running time (200 seconds). It is called by many Geant functions. It then calls several functions in gm2geom. The largest ones involve the fringe field and the storage ring field. Let’s look at the Fringe field. Figure 4.6: Fringe Field Figure 4.6 shows gm2geom::FringeField::getFringeField. Much time is spent in interpolating. Can we interpolate less? There are also calls getting services and constants. Perhaps those can be cached. Let’s look at the storage field performance too. Figure 4.7: Services Again, more constants and service handling. Perhaps there are improvements here to be made. The next step is to look at the code or do further performance testing with allinea (next section). "],
["profiling-with-allinea.html", "5 Profiling with Allinea 5.1 Downloading Allinea Forge 5.2 Running Allinea Map Data Collection", " 5 Profiling with Allinea Allinea is an advanced profiler tool for which the lab has a limited number of licenses. Anyone can install Allinea, but you will need a license file to use it for taking profiling data. Ask Adam Lyon for the file. Please keep your Allinea usage to a minimum, as we have a linited number of licenses. While Allinea is running and collecting profiling data, you are taking up a license. While you can’t collect profiling data for a linux application on your Mac, you can download Allinea for the Mac and use it to nicely view the profiling data. Doing so does not use a license. 5.1 Downloading Allinea Forge Allinea map is the profiling tool and comes with the Allinea Forge package. Go to https://www.allinea.com/products/forge/download and download and unpack the appropriate flavor of the program. Note that Scientific Linux is the same as Red Hat Enterprise Linux. For most machines, you will likely want the Red Hat Enterprise 6.0+ 64 bit download. Be sure to ask Adam for the license file. 5.2 Running Allinea Map Data Collection Note that if you are running away from the Fermilab site, you will need the Fermilab VPN in order to get a license. Launch the VPN first. Setup your development/running environment. Now run the profiler, &lt;installDir&gt;/allinea/bin/map --profile -o v7.map $ART_FQ_DIR/bin/gm2 -c mdc0.fcl -n 1000 "]
]
